{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Autoencoders (AE) en MNIST"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Importación de módulos necesarios**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import mnist\n",
    "import numpy as np\n",
    "from keras.layers import Input, Dense\n",
    "from keras.models import Model\n",
    "from keras.models import load_model\n",
    "from keras.optimizers import SGD, adadelta\n",
    "import warnings\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3.0 Creación de conjuntos de datos a utilizar**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En primer lugar, se crean los conjuntos de datos a ser utilizados en la resolución del problema. Para ello, el dataset completo de imágenes es obtenido desde el repositorio de *keras*. Posteriormente, las matrices que contienen las imágenes, *x_train* y *x_test*, son escaladas en base a la intensidad máxima de píxel y luego reorganizadas como un vector cada una.\n",
    "\n",
    "Además, se crea el conjunto de validación que será usado más adelante, extrayendo para ello los últimos 5.000 registros del conjunto de entrenamiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Se cargan conjutos de entrenamiento y de prueba\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "# Se normalizan conjuntos de datos en base a intensidad máxima de pixel\n",
    "x_train = x_train.astype('float32') / 255.\n",
    "x_test = x_test.astype('float32') / 255.\n",
    "\n",
    "# Se transforman las imágenes de ambos conjuntos a vectores\n",
    "x_train = x_train.reshape((len(x_train), np.prod(x_train.shape[1:])))\n",
    "x_test = x_test.reshape((len(x_test), np.prod(x_test.shape[1:])))\n",
    "\n",
    "# Se define conjunto de validación y se reestructura conjunto de entrenamiento\n",
    "x_val = x_train[5000:, :]\n",
    "x_train = x_train[:5000, :]\n",
    "y_val = y_train[5000:]\n",
    "y_train = y_train[:5000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.1 Reducción de dimensionalidad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En esta sección, se hará uso de diversos AE's como reductores de dimensionalidad, esperando mejorar el rendimiento de modelos convolucionales, los cuales recibirán como inputs las imágenes \"reducidas\" y serán entrenados para construir un clasificador de dígitos. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3.1.1 AE con una capa escondida**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se comienza construyendo un AE simple, compuesto únicamente por una capa oculta (enconder) y una capa de salida (decoder). En principio, el enconder utilizará la función de activación sigmoide, para luego experimentar con ReLU, al igual que el decoder. Se usará *adadelta* como método de entrenamiento y *binary crossentropy* como función de pérdida. Para la implementación del AE, se construye la función *simple_AE*, que recibe como parámetro el nivel de compresión deseado y la función de activación del encoder. Como salida, se generan archivos que registran el porcentaje de compresión obtenido y el error de reconstrucción de cada configuración.\n",
    "\n",
    "El enconder estará integrado por d' neuronas, con d' en {2, 8, 32, 64}. Esto quiere decir que el input original, de 784 dimensiones, será comprimido en un vector de d' dimensiones.\n",
    "\n",
    "El decoder en cambio, estára compuesto, naturalmente, por 784 neuronas, pues se busca restaurar la estructura inicial del input recibido."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Implementación de función simple_AE; d_ : compresión deseada; act_func: función de activación encoder\n",
    "def simple_AE(d_, act_functions):\n",
    "    # Se determina el tipo de input a ser recibido por el AE\n",
    "    input_img = Input(shape=(784,))\n",
    "    # \"encoded\" es la versión codificada del input\n",
    "    encoded = Dense(d_, activation=act_functions[0])(input_img)\n",
    "    # \"decoded\" es la reconstrucción del input codificado\n",
    "    decoded = Dense(784, activation=act_functions[1])(encoded)\n",
    "    # Se genera AE a partir de capas anteriores, el cual mapea un input hacia su reconstrucción\n",
    "    autoencoder = Model(input=input_img, output=decoded)\n",
    "    # Se definen método de entrenamiento y función de pérdida\n",
    "    autoencoder.compile(optimizer='adam', loss='binary_crossentropy')\n",
    "    # Se entrena AE\n",
    "    history = autoencoder.fit(x_train, x_train,\n",
    "              epochs=50,\n",
    "              batch_size=256,\n",
    "              shuffle=True,\n",
    "              verbose=0,\n",
    "              validation_data=(x_val, x_val))\n",
    "    # Se guardan porcentaje de compresión y error de reconstrucción en un archivo\n",
    "    autoencoder.save('basic_autoenconder_784x' + str(d_) + act_functions[0] + '_' + act_functions[1] + '.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Así, se procede a generar AE's para d' dimensiones y utilizando la función ReLU y/o sigmoide en el enconder y/o el decoder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Valores posibles para la dimensión del input comprimido\n",
    "dimensions = [2, 8, 32, 64]\n",
    "# Funciones de activación posibles\n",
    "activations = [('sigmoid', 'sigmoid'), ('relu', 'sigmoid'), ('sigmoid', 'relu')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Se generan todos los AE's posibles\n",
    "for dimension in dimensions:\n",
    "    for activation in activations:\n",
    "        simple_AE(dimension, activation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generados los archivos, se procede a leerlos para determinar el rendimiento de cada una de las configuraciones. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoder: sigmoid | Decoder: sigmoid\n",
      "Compresion: 0.00255102040816 % | Error: 0.316933655649\n",
      "Compresion: 0.0102040816327 % | Error: 0.270845110208\n",
      "Compresion: 0.0408163265306 % | Error: 0.263548591167\n",
      "Compresion: 0.0816326530612 % | Error: 0.214989810884\n",
      "\n",
      "\n",
      "Encoder: relu | Decoder: sigmoid\n",
      "Compresion: 0.00255102040816 % | Error: 0.248252324775\n",
      "Compresion: 0.0102040816327 % | Error: 0.182951631218\n",
      "Compresion: 0.0408163265306 % | Error: 0.121280142166\n",
      "Compresion: 0.0816326530612 % | Error: 0.0979144032449\n",
      "\n",
      "\n",
      "Encoder: sigmoid | Decoder: relu\n",
      "Compresion: 0.00255102040816 % | Error: 0.909125794262\n",
      "Compresion: 0.0102040816327 % | Error: 0.766526055366\n",
      "Compresion: 0.0408163265306 % | Error: 0.624800803095\n",
      "Compresion: 0.0816326530612 % | Error: 0.544563655525\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for activation in activations:\n",
    "    print('Encoder: ' + activation[0] + ' | ' + 'Decoder: ' + activation[1])\n",
    "    for dimension in dimensions:\n",
    "        autoencoder = load_model('basic_autoenconder_784x' + str(dimension) + activation[0] + '_' + activation[1] + '.h5')\n",
    "        compression = float(dimension) / 784.\n",
    "        error = autoencoder.evaluate(x_test, x_test, batch_size=10, verbose=0)\n",
    "        print('Compresion: ' + str(compression) + ' %' + ' | ' + 'Error: ' + str(error))\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En consecuencia, se observa que no es una buena práctica utilizar la función de activación relu en el decoder, pues independiente de la compresión utilizada, el error de reconstrucción es superior o igual al 54%.\n",
    "Por otro lado, los errores más bajos se consiguen al usar relu en el encoder y sigmoide en el decoder, para toda compresión posible.\n",
    "Es importante notar que si la compresión es demasiado alta (es decir, si el input codificado posee una baja dimensionalidad), el error aumenta, como ocurre para d' = 2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3.1.2 Comparando reconstrucciones de imágenes**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Se desea comparar la \"calidad\" de reconstrucción de los autoencoders implementados en la sección anterior sobre algunas imágenes del conjunto de pruebas. Considerando que al utilizar la función de activación ReLU en el encoder y sigmoide en en el decoder se obtienen los errores de reconstrucción más bajos, se recuperarán los cuatro modelos que hacen uso de esta configuación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se recuperan autoencoders de encoder ReLU y decoder sigmoide, para cada d' posible\n",
    "autoencoder_784x2 = load_model('basic_autoenconder_784x2relu_sigmoid.h5')\n",
    "autoencoder_784x8 = load_model('basic_autoenconder_784x8relu_sigmoid.h5')\n",
    "autoencoder_784x32 = load_model('basic_autoenconder_784x32relu_sigmoid.h5')\n",
    "autoencoder_784x64 = load_model('basic_autoenconder_784x64relu_sigmoid.h5')\n",
    "\n",
    "autoencoders = {}\n",
    "autoencoders['autoencoder_784x2'] = autoencoder_784x2\n",
    "autoencoders['autoencoder_784x8'] = autoencoder_784x8\n",
    "autoencoders['autoencoder_784x32'] = autoencoder_784x32\n",
    "autoencoders['autoencoder_784x64'] = autoencoder_784x64"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Luego, se continúa con la implementación de forma separada de un encoder y un decoder para cada d' posible. Para ello, se crean las funciones *make_encoder* y *make_autoencoder*, que reciben como parámetro d' y la función de activación deseada, en cada caso."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Función para creación de encoder\n",
    "def make_encoder(d_, act_function):\n",
    "    input_img = Input(shape=(784,))\n",
    "    encoded = Dense(d_, activation=act_function)(input_img)\n",
    "    # Se define encoder, el cual mapea un input hacia su versión codificada\n",
    "    encoder = Model(input=input_img, outputs=encoded)\n",
    "    return encoder\n",
    "\n",
    "# Función para creación de encoder\n",
    "def make_decoder(d_, act_function, autoencoder):\n",
    "    # encoded_input: Capa que permite la entrada de un input codificado en 32 dimensiones\n",
    "    encoded_input = Input(shape=(d_,))\n",
    "    # Se recupera última capa de autoencoder\n",
    "    decoder_layer = autoencoder.layers[-1]\n",
    "    # Se define decoder, el cual mapea un input comprimido hacia su versión \"original\"\n",
    "    decoder = Model(input=encoded_input, output=decoder_layer(encoded_input))\n",
    "    return decoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Así, para cada d' posible, se estudian dos imágenes del conjunto de pruebas. Por cada una, se comparan su versión original y su reconstrucción. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "encoder_act_function = 'relu'\n",
    "decoder_act_function = 'sigmoid'\n",
    "n = 2 # Cantidad de imágenes a estudiar por cada d'\n",
    "\n",
    "for dimension in dimensions:\n",
    "    print(\"Imagenes para d' = \", dimension)\n",
    "    autoencoder = autoencoders['autoencoder_784_x' + dimension]\n",
    "    encoder = make_encoder(dimension, encoder_act_function)\n",
    "    decoder = make_decoder(dimension, decoder_act_function, autoencoder)\n",
    "    encoded_test = encoder.predict(x_test)\n",
    "    decoded_test = decoder.predict(encoded_test)\n",
    "    plt.figure(figsize=(20, 4))\n",
    "    for in in range(n):\n",
    "        ax = plt.subplot(2, n, i + 1)\n",
    "        plt.imshow(x_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
