{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.3 Pre-entrenamiento "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En esta sección, se implementarán diversos AE con el fin de pre-entrenar redes profundas. De esta forma, se espera poder regularizar un modelo determinado, buscando evitar que este sufra de overfitting. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Importación de módulos necesarios**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.datasets import mnist\n",
    "from keras.layers import Dense, Input\n",
    "from keras.models import Sequential, Model, load_model, save_model\n",
    "from keras.utils import np_utils\n",
    "from keras.optimizers import SGD\n",
    "import numpy as np\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3.3.0 Creación de conjuntos de datos a utilizar**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Análogamente a las secciones 3.1 y 3.2, se construyen los conjuntos de entrenamiento, validación y prueba."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se cargan conjutos de entrenamiento y de prueba\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "# Se normalizan conjuntos de datos en base a intensidad máxima de pixel\n",
    "x_train = x_train.astype('float32') / 255.\n",
    "x_test = x_test.astype('float32') / 255.\n",
    "\n",
    "# Se transforman las imágenes de ambos conjuntos a vectores\n",
    "x_train = x_train.reshape((len(x_train), np.prod(x_train.shape[1:])))\n",
    "x_test = x_test.reshape((len(x_test), np.prod(x_test.shape[1:])))\n",
    "\n",
    "# Se define conjunto de validación y se reestructura conjunto de entrenamiento\n",
    "x_val = x_train[:5000, :]\n",
    "x_train = x_train[5000:, :]\n",
    "y_val = y_train[:5000]\n",
    "y_train = y_train[5000:]\n",
    "\n",
    "# Vectores y_train, y_val e y_test son transformados en matrices categóricas\n",
    "y_train_ = np_utils.to_categorical(y_train)\n",
    "y_val_ = np_utils.to_categorical(y_val)\n",
    "y_test_ = np_utils.to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3.3.1 Definición de modelo a ser pre-entrenado**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En primer lugar, se diseña la red neuronal que será pre-entrenada. Está será una red FF de dos capas ocultas, las que poseerán 1000 neuronas, cada una. La función de activación de las neuronas será sigmoide. La capa de salida estará conformada por 10 neuronas (una por cada dígito), las que serán activadas por medio de la función softmax.\n",
    "\n",
    "Para efectos comparativos, se entrenará la red sin pre-entrenamiento y se determinará el error de clasificación sobre el conjunto de pruebas. Este entrenamiento será llevado cabo a través del método de optimización *adam*, 50 epochs, batches de tamaño 25 y categorical crossentropy como función de pérdida. **Notar que a pesar de que se dió la instrucción de utilizar SGD, esto no ha sido posible, ya que al entrenar el modelo con este método, las tasas de error obtenidas (tanto de entrenamiento como de validación) eran cercanas al 91%**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 55000 samples, validate on 5000 samples\n",
      "Epoch 1/50\n",
      "55000/55000 [==============================] - 41s - loss: 0.3219 - acc: 0.9007 - val_loss: 0.1339 - val_acc: 0.9584\n",
      "Epoch 2/50\n",
      "55000/55000 [==============================] - 41s - loss: 0.1259 - acc: 0.9615 - val_loss: 0.1091 - val_acc: 0.9682\n",
      "Epoch 3/50\n",
      "55000/55000 [==============================] - 41s - loss: 0.0790 - acc: 0.9755 - val_loss: 0.0898 - val_acc: 0.9728\n",
      "Epoch 4/50\n",
      "55000/55000 [==============================] - 42s - loss: 0.0542 - acc: 0.9827 - val_loss: 0.0759 - val_acc: 0.9776\n",
      "Epoch 5/50\n",
      "55000/55000 [==============================] - 42s - loss: 0.0388 - acc: 0.9874 - val_loss: 0.0703 - val_acc: 0.9802\n",
      "Epoch 6/50\n",
      "55000/55000 [==============================] - 43s - loss: 0.0297 - acc: 0.9900 - val_loss: 0.0924 - val_acc: 0.9744\n",
      "Epoch 7/50\n",
      "55000/55000 [==============================] - 43s - loss: 0.0229 - acc: 0.9923 - val_loss: 0.0767 - val_acc: 0.9814\n",
      "Epoch 8/50\n",
      "55000/55000 [==============================] - 42s - loss: 0.0174 - acc: 0.9944 - val_loss: 0.0830 - val_acc: 0.9818\n",
      "Epoch 9/50\n",
      "55000/55000 [==============================] - 38s - loss: 0.0150 - acc: 0.9947 - val_loss: 0.0978 - val_acc: 0.9804\n",
      "Epoch 10/50\n",
      "55000/55000 [==============================] - 40s - loss: 0.0122 - acc: 0.9961 - val_loss: 0.0957 - val_acc: 0.9788\n",
      "Epoch 11/50\n",
      "55000/55000 [==============================] - 42s - loss: 0.0108 - acc: 0.9964 - val_loss: 0.1062 - val_acc: 0.9790\n",
      "Epoch 12/50\n",
      "55000/55000 [==============================] - 42s - loss: 0.0104 - acc: 0.9964 - val_loss: 0.0902 - val_acc: 0.9814\n",
      "Epoch 13/50\n",
      "55000/55000 [==============================] - 42s - loss: 0.0068 - acc: 0.9979 - val_loss: 0.0923 - val_acc: 0.9806\n",
      "Epoch 14/50\n",
      "55000/55000 [==============================] - 42s - loss: 0.0077 - acc: 0.9976 - val_loss: 0.1051 - val_acc: 0.9826\n",
      "Epoch 15/50\n",
      "55000/55000 [==============================] - 42s - loss: 0.0065 - acc: 0.9980 - val_loss: 0.0843 - val_acc: 0.9838\n",
      "Epoch 16/50\n",
      "55000/55000 [==============================] - 42s - loss: 0.0070 - acc: 0.9976 - val_loss: 0.1307 - val_acc: 0.9798\n",
      "Epoch 17/50\n",
      "55000/55000 [==============================] - 42s - loss: 0.0074 - acc: 0.9977 - val_loss: 0.0943 - val_acc: 0.9828\n",
      "Epoch 18/50\n",
      "55000/55000 [==============================] - 42s - loss: 0.0045 - acc: 0.9986 - val_loss: 0.1036 - val_acc: 0.9832\n",
      "Epoch 19/50\n",
      "55000/55000 [==============================] - 42s - loss: 0.0048 - acc: 0.9985 - val_loss: 0.1347 - val_acc: 0.9804\n",
      "Epoch 20/50\n",
      "55000/55000 [==============================] - 42s - loss: 0.0072 - acc: 0.9980 - val_loss: 0.1110 - val_acc: 0.9822\n",
      "Epoch 21/50\n",
      "55000/55000 [==============================] - 43s - loss: 0.0024 - acc: 0.9993 - val_loss: 0.1002 - val_acc: 0.9830\n",
      "Epoch 22/50\n",
      "55000/55000 [==============================] - 42s - loss: 0.0082 - acc: 0.9980 - val_loss: 0.1165 - val_acc: 0.9814\n",
      "Epoch 23/50\n",
      "55000/55000 [==============================] - 42s - loss: 0.0032 - acc: 0.9992 - val_loss: 0.1187 - val_acc: 0.9822\n",
      "Epoch 24/50\n",
      "55000/55000 [==============================] - 41s - loss: 0.0056 - acc: 0.9984 - val_loss: 0.1104 - val_acc: 0.9836\n",
      "Epoch 25/50\n",
      "55000/55000 [==============================] - 43s - loss: 0.0049 - acc: 0.9985 - val_loss: 0.1012 - val_acc: 0.9868\n",
      "Epoch 26/50\n",
      "55000/55000 [==============================] - 42s - loss: 0.0033 - acc: 0.9990 - val_loss: 0.1070 - val_acc: 0.9842\n",
      "Epoch 27/50\n",
      "55000/55000 [==============================] - 40s - loss: 0.0065 - acc: 0.9983 - val_loss: 0.1042 - val_acc: 0.9854\n",
      "Epoch 28/50\n",
      "55000/55000 [==============================] - 39s - loss: 0.0023 - acc: 0.9994 - val_loss: 0.1043 - val_acc: 0.9856\n",
      "Epoch 29/50\n",
      "55000/55000 [==============================] - 41s - loss: 0.0046 - acc: 0.9986 - val_loss: 0.1114 - val_acc: 0.9846\n",
      "Epoch 30/50\n",
      "55000/55000 [==============================] - 40s - loss: 0.0033 - acc: 0.9991 - val_loss: 0.1125 - val_acc: 0.9836\n",
      "Epoch 31/50\n",
      "55000/55000 [==============================] - 42s - loss: 0.0040 - acc: 0.9990 - val_loss: 0.1121 - val_acc: 0.9846\n",
      "Epoch 32/50\n",
      "55000/55000 [==============================] - 40s - loss: 0.0025 - acc: 0.9994 - val_loss: 0.1180 - val_acc: 0.9834\n",
      "Epoch 33/50\n",
      "55000/55000 [==============================] - 40s - loss: 0.0036 - acc: 0.9989 - val_loss: 0.0986 - val_acc: 0.9860\n",
      "Epoch 34/50\n",
      "55000/55000 [==============================] - 41s - loss: 0.0027 - acc: 0.9994 - val_loss: 0.1282 - val_acc: 0.9818\n",
      "Epoch 35/50\n",
      "55000/55000 [==============================] - 42s - loss: 0.0044 - acc: 0.9988 - val_loss: 0.1243 - val_acc: 0.9830\n",
      "Epoch 36/50\n",
      "55000/55000 [==============================] - 42s - loss: 0.0038 - acc: 0.9990 - val_loss: 0.1219 - val_acc: 0.9836\n",
      "Epoch 37/50\n",
      "55000/55000 [==============================] - 42s - loss: 0.0028 - acc: 0.9992 - val_loss: 0.1267 - val_acc: 0.9834\n",
      "Epoch 38/50\n",
      "55000/55000 [==============================] - 40s - loss: 0.0040 - acc: 0.9987 - val_loss: 0.1369 - val_acc: 0.9838\n",
      "Epoch 39/50\n",
      "55000/55000 [==============================] - 41s - loss: 0.0017 - acc: 0.9995 - val_loss: 0.1390 - val_acc: 0.9828\n",
      "Epoch 40/50\n",
      "55000/55000 [==============================] - 41s - loss: 0.0046 - acc: 0.9989 - val_loss: 0.1483 - val_acc: 0.9804\n",
      "Epoch 41/50\n",
      "55000/55000 [==============================] - 41s - loss: 0.0035 - acc: 0.9991 - val_loss: 0.1287 - val_acc: 0.9834\n",
      "Epoch 42/50\n",
      "55000/55000 [==============================] - 41s - loss: 0.0031 - acc: 0.9991 - val_loss: 0.1337 - val_acc: 0.9824\n",
      "Epoch 43/50\n",
      "55000/55000 [==============================] - 42s - loss: 0.0029 - acc: 0.9993 - val_loss: 0.1176 - val_acc: 0.9850\n",
      "Epoch 44/50\n",
      "55000/55000 [==============================] - 44s - loss: 0.0024 - acc: 0.9994 - val_loss: 0.1065 - val_acc: 0.9856\n",
      "Epoch 45/50\n",
      "55000/55000 [==============================] - 40s - loss: 0.0034 - acc: 0.9994 - val_loss: 0.1600 - val_acc: 0.9816\n",
      "Epoch 46/50\n",
      "55000/55000 [==============================] - 42s - loss: 0.0042 - acc: 0.9988 - val_loss: 0.1249 - val_acc: 0.9836\n",
      "Epoch 47/50\n",
      "55000/55000 [==============================] - 41s - loss: 0.0026 - acc: 0.9995 - val_loss: 0.1401 - val_acc: 0.9830\n",
      "Epoch 48/50\n",
      "55000/55000 [==============================] - 42s - loss: 0.0036 - acc: 0.9990 - val_loss: 0.1274 - val_acc: 0.9844\n",
      "Epoch 49/50\n",
      "55000/55000 [==============================] - 42s - loss: 0.0019 - acc: 0.9995 - val_loss: 0.1275 - val_acc: 0.9822\n",
      "Epoch 50/50\n",
      "55000/55000 [==============================] - 42s - loss: 0.0019 - acc: 0.9996 - val_loss: 0.1273 - val_acc: 0.9834\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f76752a8250>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Se define red vacía\n",
    "model = Sequential()\n",
    "# Se agregan capas ocultas\n",
    "model.add(Dense(1000, activation='sigmoid', input_shape=(784,)))\n",
    "model.add(Dense(1000, activation='sigmoid'))\n",
    "# Se agrega capa de salida\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "# Se definen parámetros de entrenamiento\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "# Se entrena modelo\n",
    "model.fit(x_train, y_train_, epochs=50, batch_size=25, shuffle=True, validation_data=(x_val, y_val_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 9760/10000 [============================>.] - ETA: 0s\n",
      "Error de clasificacion sobre conjunto de pruebas:  1.79 %\n"
     ]
    }
   ],
   "source": [
    "# Se determina error de clasificación sobre conjunto de pruebas\n",
    "model_scores = model.evaluate(x_test, y_test_)\n",
    "print '\\nError de clasificacion sobre conjunto de pruebas: ', (1 - model_scores[1]) * 100, '%'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Así, el entrenamiento finaliza con función de pérdida 0,0019 y error de clasificación de entrenamiento de un 0,04%. Además, el error de clasificación sobre el conjunto de pruebas es de un 1,79%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3.3.2 Pre-entrenando el modelo**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Con el fin de mejorar el error de clasificación, se pre-entrenará la red diseñada en la sección anterior. Como dicha red posee dos capas ocultas, se utilizarán dos autoencoders, cada uno encargado de pre-entrenar los pesos de una y sólo una de las capas. Para llevar a cabo esta tarea, se implementa la función *pre_training*, la que recibe el nombre de la función de activación a ser utilizada tanto en los autoencoders como en el modelo. Como resultado de este proceso, el modelo de la sección anterior será entrenado de tal manera que los pesos de cada capa oculta serán los mismos que pre-entrenó el autoencoder respectivo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pre_training permite el pre-entrenamiento de una red FF\n",
    "def pre_training(encoder_activation, decoder_activation=None):\n",
    "    \n",
    "    if not decoder_activation:\n",
    "        decoder_activation = encoder_activation\n",
    "    \n",
    "    # Se implementa primer autoencoder, encargado de pre-entrenar primera capa oculta\n",
    "    # Se define input a ser recibido por autoencoder\n",
    "    input_img1 = Input(shape=(784, ))\n",
    "    # Se define capa encoder \n",
    "    encoded1 = Dense(1000, activation=encoder_activation)(input_img1)\n",
    "    # Se define capa decoder\n",
    "    decoded1 = Dense(784, activation=decoder_activation)(encoded1)\n",
    "    # Se define autoencoder\n",
    "    autoencoder1 = Model(input=input_img1, output=decoded1)\n",
    "    # Se define encoder por separado\n",
    "    encoder1 = Model(input_img1, output=encoded1)\n",
    "    # Se definen parámetros de pre-entrenamiento\n",
    "    autoencoder1.compile(optimizer='adam', loss='binary_crossentropy')\n",
    "    # Se pre-entrena primer autoencoder\n",
    "    autoencoder1.fit(x_train, x_train, epochs=50, batch_size=25, shuffle=True, verbose=0, validation_data=(x_val, x_val))\n",
    "    encoded_input1 = Input(shape=(1000, ))\n",
    "    # Se guardan autoencoder y encoder en archivos\n",
    "    autoencoder1.save('autoencoder_1_' + encoder_activation + '.h5')\n",
    "    encoder1.save('encoder_1_' + encoder_activation + '.h5')\n",
    "    \n",
    "    # Se implementa segundo autoencoder, encargado de pre-entrenar segunda capa oculta\n",
    "    # Primero, se obtienen las salidas generadas por el encoder del primer autoencoder para cada conjunto de datos\n",
    "    x_train_encoded1 = encoder1.predict(x_train)\n",
    "    x_val_encoded1 = encoder1.predict(x_val)\n",
    "    x_test_encoded1 = encoder1.predict(x_test)\n",
    "\n",
    "    # Se define input a ser recibido por autoencoder\n",
    "    input_img2 = Input(shape=(1000, ))\n",
    "    # Se define capa encoder\n",
    "    encoded2 = Dense(1000, activation=encoder_activation)(input_img2)\n",
    "    # Se define capa decoder\n",
    "    decoded2 = Dense(1000, activation=decoder_activation)(encoded2)\n",
    "    # Se define autoencoder\n",
    "    autoencoder2 = Model(input=input_img2, output=decoded2)\n",
    "    # Se define encoder por separado\n",
    "    encoder2 = Model(input=input_img2, output=encoded2)\n",
    "    # Se especifican parámetros de optimización\n",
    "    autoencoder2.compile(optimizer='adam', loss='binary_crossentropy')\n",
    "    # Se pre-entrena segundo autoencoder\n",
    "    autoencoder2.fit(x_train_encoded1, x_train_encoded1, epochs=50, batch_size=25, shuffle=True, verbose=0,\n",
    "                 validation_data=(x_val_encoded1, x_val_encoded1))\n",
    "    encoded_input2 = Input(shape=(1000, ))\n",
    "    autoencoder2.save('autoencoder_2_' + encoder_activation + '.h5')\n",
    "    encoder2.save('encoder_2_' + encoder_activation + '.h5')\n",
    "\n",
    "    # Finalmente, se entrena modelo a partir de pesos pre-entrenados\n",
    "    model = Sequential()\n",
    "    # Se agrega primera capa oculta\n",
    "    model.add(Dense(1000, activation=encoder_activation, input_shape=(784, )))\n",
    "    # Los pesos de la primera capa oculta son igualados a pesos pre-entrenados por primer autoencoder\n",
    "    model.layers[-1].set_weights(autoencoder1.layers[1].get_weights())\n",
    "    # Se agrega segunda capa oculta\n",
    "    model.add(Dense(1000, activation=encoder_activation))\n",
    "    # Los pesos de la segunda capa oculta son igualados a pesos pre-entrenados por segundo autoencoder\n",
    "    model.layers[-1].set_weights(autoencoder2.layers[1].get_weights())\n",
    "    # Se define capa de salida\n",
    "    model.add(Dense(10, activation='softmax'))\n",
    "    # Se especifican parámetros de optimización\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    # Se entrena modeo\n",
    "    model.fit(x_train, y_train_, epochs=20, batch_size=25, shuffle=True, verbose=1 , validation_data=(x_val, y_val_))\n",
    "    # Se guarda modelo entrenado en archivo\n",
    "    model.save('Net-784x1000x1000x10-finetunned_' + encoder_activation + '.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Así, se ejecuta el proceso descrito sobre el modelo de la sección anterior utilizando la función de activación sigmoide tanto en los autoencoders como en las capas ocultas del modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 55000 samples, validate on 5000 samples\n",
      "Epoch 1/20\n",
      "55000/55000 [==============================] - 41s - loss: 0.2367 - acc: 0.9277 - val_loss: 0.1243 - val_acc: 0.9630\n",
      "Epoch 2/20\n",
      "55000/55000 [==============================] - 41s - loss: 0.0889 - acc: 0.9722 - val_loss: 0.0866 - val_acc: 0.9728\n",
      "Epoch 3/20\n",
      "55000/55000 [==============================] - 41s - loss: 0.0537 - acc: 0.9831 - val_loss: 0.0817 - val_acc: 0.9742\n",
      "Epoch 4/20\n",
      "55000/55000 [==============================] - 41s - loss: 0.0360 - acc: 0.9883 - val_loss: 0.0769 - val_acc: 0.9796\n",
      "Epoch 5/20\n",
      "55000/55000 [==============================] - 41s - loss: 0.0243 - acc: 0.9920 - val_loss: 0.0764 - val_acc: 0.9802\n",
      "Epoch 6/20\n",
      "55000/55000 [==============================] - 41s - loss: 0.0198 - acc: 0.9935 - val_loss: 0.0696 - val_acc: 0.9816\n",
      "Epoch 7/20\n",
      "55000/55000 [==============================] - 41s - loss: 0.0156 - acc: 0.9944 - val_loss: 0.0691 - val_acc: 0.9826\n",
      "Epoch 8/20\n",
      "55000/55000 [==============================] - 42s - loss: 0.0123 - acc: 0.9960 - val_loss: 0.0906 - val_acc: 0.9786\n",
      "Epoch 9/20\n",
      "55000/55000 [==============================] - 42s - loss: 0.0097 - acc: 0.9967 - val_loss: 0.0829 - val_acc: 0.9836\n",
      "Epoch 10/20\n",
      "55000/55000 [==============================] - 43s - loss: 0.0098 - acc: 0.9965 - val_loss: 0.1009 - val_acc: 0.9780\n",
      "Epoch 11/20\n",
      "55000/55000 [==============================] - 39s - loss: 0.0093 - acc: 0.9969 - val_loss: 0.0880 - val_acc: 0.9836\n",
      "Epoch 12/20\n",
      "55000/55000 [==============================] - 39s - loss: 0.0073 - acc: 0.9973 - val_loss: 0.0826 - val_acc: 0.9816\n",
      "Epoch 13/20\n",
      "55000/55000 [==============================] - 39s - loss: 0.0066 - acc: 0.9979 - val_loss: 0.0781 - val_acc: 0.9836\n",
      "Epoch 14/20\n",
      "55000/55000 [==============================] - 40s - loss: 0.0061 - acc: 0.9979 - val_loss: 0.0919 - val_acc: 0.9838\n",
      "Epoch 15/20\n",
      "55000/55000 [==============================] - 40s - loss: 0.0059 - acc: 0.9979 - val_loss: 0.0970 - val_acc: 0.9830\n",
      "Epoch 16/20\n",
      "55000/55000 [==============================] - 40s - loss: 0.0072 - acc: 0.9976 - val_loss: 0.1399 - val_acc: 0.9800\n",
      "Epoch 17/20\n",
      "55000/55000 [==============================] - 40s - loss: 0.0044 - acc: 0.9986 - val_loss: 0.0855 - val_acc: 0.9846\n",
      "Epoch 18/20\n",
      "55000/55000 [==============================] - 40s - loss: 0.0050 - acc: 0.9985 - val_loss: 0.0851 - val_acc: 0.9852\n",
      "Epoch 19/20\n",
      "55000/55000 [==============================] - 40s - loss: 0.0053 - acc: 0.9983 - val_loss: 0.1052 - val_acc: 0.9842\n",
      "Epoch 20/20\n",
      "55000/55000 [==============================] - 40s - loss: 0.0045 - acc: 0.9985 - val_loss: 0.1229 - val_acc: 0.9792\n",
      " 9600/10000 [===========================>..] - ETA: 0s\n",
      "Error de clasificacion sobre conjunto de pruebas:  2.29 %\n"
     ]
    }
   ],
   "source": [
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "pre_training('sigmoid')\n",
    "model_sigmoid = load_model('Net-784x1000x1000x10-finetunned_sigmoid.h5')\n",
    "model_sigmoid_scores = model_sigmoid.evaluate(x_test, y_test_)\n",
    "print '\\nError de clasificacion sobre conjunto de pruebas: ', (1 - model_sigmoid_scores[1]) * 100, '%'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se ve entonces que ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3.3.3 Pre-entrenamiento vía *denoising autoencoder***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 55000 samples, validate on 5000 samples\n",
      "Epoch 1/20\n",
      "55000/55000 [==============================] - 38s - loss: 0.2519 - acc: 0.9237 - val_loss: 0.1382 - val_acc: 0.9596\n",
      "Epoch 2/20\n",
      "55000/55000 [==============================] - 38s - loss: 0.1325 - acc: 0.9594 - val_loss: 0.1143 - val_acc: 0.9668\n",
      "Epoch 3/20\n",
      "55000/55000 [==============================] - 38s - loss: 0.1108 - acc: 0.9659 - val_loss: 0.1159 - val_acc: 0.9686\n",
      "Epoch 4/20\n",
      "55000/55000 [==============================] - 39s - loss: 0.0943 - acc: 0.9705 - val_loss: 0.1024 - val_acc: 0.9726\n",
      "Epoch 5/20\n",
      "55000/55000 [==============================] - 39s - loss: 0.0826 - acc: 0.9747 - val_loss: 0.1101 - val_acc: 0.9654\n",
      "Epoch 6/20\n",
      "55000/55000 [==============================] - 39s - loss: 0.0747 - acc: 0.9769 - val_loss: 0.1044 - val_acc: 0.9716\n",
      "Epoch 7/20\n",
      "55000/55000 [==============================] - 40s - loss: 0.0712 - acc: 0.9767 - val_loss: 0.1284 - val_acc: 0.9684\n",
      "Epoch 8/20\n",
      "55000/55000 [==============================] - 40s - loss: 0.0630 - acc: 0.9791 - val_loss: 0.1229 - val_acc: 0.9686\n",
      "Epoch 9/20\n",
      "55000/55000 [==============================] - 40s - loss: 0.0641 - acc: 0.9798 - val_loss: 0.1185 - val_acc: 0.9714\n",
      "Epoch 10/20\n",
      "55000/55000 [==============================] - 40s - loss: 0.0573 - acc: 0.9819 - val_loss: 0.1106 - val_acc: 0.9716\n",
      "Epoch 11/20\n",
      "55000/55000 [==============================] - 40s - loss: 0.0576 - acc: 0.9822 - val_loss: 0.1257 - val_acc: 0.9702\n",
      "Epoch 12/20\n",
      "55000/55000 [==============================] - 40s - loss: 0.0549 - acc: 0.9829 - val_loss: 0.1259 - val_acc: 0.9698\n",
      "Epoch 13/20\n",
      "55000/55000 [==============================] - 40s - loss: 0.0516 - acc: 0.9838 - val_loss: 0.1337 - val_acc: 0.9668\n",
      "Epoch 14/20\n",
      "55000/55000 [==============================] - 40s - loss: 0.0472 - acc: 0.9847 - val_loss: 0.1247 - val_acc: 0.9694\n",
      "Epoch 15/20\n",
      "55000/55000 [==============================] - 40s - loss: 0.0499 - acc: 0.9840 - val_loss: 0.1206 - val_acc: 0.9696\n",
      "Epoch 16/20\n",
      "55000/55000 [==============================] - 40s - loss: 0.0474 - acc: 0.9851 - val_loss: 0.1383 - val_acc: 0.9718\n",
      "Epoch 17/20\n",
      "55000/55000 [==============================] - 40s - loss: 0.0446 - acc: 0.9860 - val_loss: 0.1176 - val_acc: 0.9740\n",
      "Epoch 18/20\n",
      "55000/55000 [==============================] - 40s - loss: 0.0453 - acc: 0.9861 - val_loss: 0.1190 - val_acc: 0.9744\n",
      "Epoch 19/20\n",
      "55000/55000 [==============================] - 40s - loss: 0.0480 - acc: 0.9856 - val_loss: 0.1312 - val_acc: 0.9734\n",
      "Epoch 20/20\n",
      "55000/55000 [==============================] - 40s - loss: 0.0445 - acc: 0.9863 - val_loss: 0.1261 - val_acc: 0.9726\n",
      " 9888/10000 [============================>.] - ETA: 0s \n",
      "Error de clasificacion sobre conjunto de pruebas:  2.82 %\n"
     ]
    }
   ],
   "source": [
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "pre_training('tanh')\n",
    "model_tanh = load_model('Net-784x1000x1000x10-finetunned_tanh.h5')\n",
    "model_tanh_scores = model_tanh.evaluate(x_test, y_test_)\n",
    "print '\\nError de clasificacion sobre conjunto de pruebas: ', (1 - model_tanh_scores[1]) * 100, '%'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recordando que es una mala práctica..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 55000 samples, validate on 5000 samples\n",
      "Epoch 1/20\n",
      "55000/55000 [==============================] - 38s - loss: 0.2207 - acc: 0.9394 - val_loss: 0.0947 - val_acc: 0.9704\n",
      "Epoch 2/20\n",
      "55000/55000 [==============================] - 39s - loss: 0.0782 - acc: 0.9758 - val_loss: 0.0998 - val_acc: 0.9744\n",
      "Epoch 3/20\n",
      "55000/55000 [==============================] - 39s - loss: 0.0563 - acc: 0.9825 - val_loss: 0.1028 - val_acc: 0.9758\n",
      "Epoch 4/20\n",
      "55000/55000 [==============================] - 40s - loss: 0.0430 - acc: 0.9866 - val_loss: 0.0860 - val_acc: 0.9788\n",
      "Epoch 5/20\n",
      "55000/55000 [==============================] - 40s - loss: 0.0333 - acc: 0.9895 - val_loss: 0.0985 - val_acc: 0.9796\n",
      "Epoch 6/20\n",
      "55000/55000 [==============================] - 40s - loss: 0.0311 - acc: 0.9909 - val_loss: 0.1206 - val_acc: 0.9766\n",
      "Epoch 7/20\n",
      "55000/55000 [==============================] - 40s - loss: 0.0324 - acc: 0.9911 - val_loss: 0.1204 - val_acc: 0.9776\n",
      "Epoch 8/20\n",
      "55000/55000 [==============================] - 40s - loss: 0.0234 - acc: 0.9939 - val_loss: 0.1235 - val_acc: 0.9792\n",
      "Epoch 9/20\n",
      "55000/55000 [==============================] - 40s - loss: 0.0263 - acc: 0.9932 - val_loss: 0.1392 - val_acc: 0.9804\n",
      "Epoch 10/20\n",
      "55000/55000 [==============================] - 40s - loss: 0.0276 - acc: 0.9935 - val_loss: 0.1267 - val_acc: 0.9814\n",
      "Epoch 11/20\n",
      "55000/55000 [==============================] - 40s - loss: 0.0204 - acc: 0.9951 - val_loss: 0.1380 - val_acc: 0.9804\n",
      "Epoch 12/20\n",
      "55000/55000 [==============================] - 40s - loss: 0.0257 - acc: 0.9945 - val_loss: 0.1502 - val_acc: 0.9796\n",
      "Epoch 13/20\n",
      "55000/55000 [==============================] - 40s - loss: 0.0264 - acc: 0.9948 - val_loss: 0.1380 - val_acc: 0.9808\n",
      "Epoch 14/20\n",
      "55000/55000 [==============================] - 40s - loss: 0.0227 - acc: 0.9955 - val_loss: 0.1612 - val_acc: 0.9806\n",
      "Epoch 15/20\n",
      "55000/55000 [==============================] - 40s - loss: 0.0287 - acc: 0.9947 - val_loss: 0.1311 - val_acc: 0.9842\n",
      "Epoch 16/20\n",
      "55000/55000 [==============================] - 40s - loss: 0.0243 - acc: 0.9956 - val_loss: 0.1517 - val_acc: 0.9810\n",
      "Epoch 17/20\n",
      "55000/55000 [==============================] - 40s - loss: 0.0229 - acc: 0.9959 - val_loss: 0.1773 - val_acc: 0.9792\n",
      "Epoch 18/20\n",
      "55000/55000 [==============================] - 40s - loss: 0.0243 - acc: 0.9959 - val_loss: 0.2084 - val_acc: 0.9760\n",
      "Epoch 19/20\n",
      "55000/55000 [==============================] - 40s - loss: 0.0239 - acc: 0.9960 - val_loss: 0.2064 - val_acc: 0.9792\n",
      "Epoch 20/20\n",
      "55000/55000 [==============================] - 41s - loss: 0.0216 - acc: 0.9966 - val_loss: 0.1703 - val_acc: 0.9832\n",
      " 9824/10000 [============================>.] - ETA: 0s\n",
      "Error de clasificacion sobre conjunto de pruebas:  1.94 %\n"
     ]
    }
   ],
   "source": [
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "pre_training('relu', 'sigmoid')\n",
    "model_relu = load_model('Net-784x1000x1000x10-finetunned_relu.h5')\n",
    "model_relu_scores = model_relu.evaluate(x_test, y_test_)\n",
    "print '\\nError de clasificacion sobre conjunto de pruebas: ', (1 - model_relu_scores[1]) * 100, '%'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
